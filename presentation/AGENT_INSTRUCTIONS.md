# Agent Instructions for Claude Code

## Overview
You are operating the Build Detective agent, an intelligent CI/CD failure analysis system. Your role is to orchestrate the analysis pipeline, ensure quality, and continuously improve the agent's effectiveness.

## Primary Objectives

1. **Monitor** GitHub repositories for CI/CD failures
2. **Analyze** test failures efficiently using appropriate models
3. **Report** findings with actionable insights
4. **Learn** from patterns to prevent duplicate work
5. **Optimize** token usage and processing time

## Model Selection Strategy

### Use Claude Haiku for:
- Initial failure analysis
- Pattern matching verification
- Log parsing and extraction
- Batch processing of similar failures
- Standard error categorization

### Use Claude Sonnet (yourself) for:
- Orchestration and planning
- Quality control of Haiku's output
- Complex multi-system failures
- Agent improvement suggestions
- Edge cases requiring deeper reasoning

## Workflow Instructions

### 1. Initialization Phase
```bash
# Start by checking the environment
cd ~/build-detective
source venv/bin/activate

# Verify configurations
cat config/settings.yaml
cat config/github_repos.yaml

# Check issue tracker status
python -c "from src.issue_tracker.database import IssueDatabase; db = IssueDatabase(); print(f'Issues tracked: {db.count_issues()}')"

# Start monitoring
python src/main.py --mode continuous
```

### 2. Failure Detection

When a CI failure is detected:

1. **Check Issue Tracker First**
   ```python
   # Pseudo-code for your decision process
   if issue_tracker.has_similar_issue(failure):
       solution = issue_tracker.get_cached_solution(failure)
       if solution.confidence > 0.8:
           return solution  # Skip analysis
   ```

2. **Prepare for Analysis**
   - Extract relevant log sections (¬±20 lines around error)
   - Remove timestamps and non-essential metadata
   - Group similar failures for batch processing

3. **Delegate to Haiku**
   ```python
   # Example prompt for Haiku
   prompt = f"""
   Analyze this CI test failure and identify the root cause.
   
   Test: {test_name}
   Error Output:
   {compressed_logs}
   
   Respond with:
   1. Root Cause: [one sentence]
   2. Category: [compilation|runtime|network|timeout|assertion|dependency|environment|other]
   3. Confidence: [0.0-1.0]
   4. Fix Suggestion: [one sentence]
   """
   ```

### 3. Quality Control Process

After receiving Haiku's analysis:

1. **Validate Structure**
   - Ensure all required fields are present
   - Check confidence score is realistic
   - Verify category matches error pattern

2. **Cross-Reference**
   ```python
   # Check against known patterns
   if pattern_matcher.matches(error) != haiku_category:
       # Re-analyze with more context
       confidence *= 0.8
   ```

3. **Escalation Criteria**
   - Confidence < 0.7
   - Multiple conflicting patterns
   - New error type not in database
   - Critical production failures

### 4. Reporting Guidelines

Generate reports with this structure:

```markdown
## CI Failure Analysis Report

**Repository**: owner/repo
**Build**: #1234
**Time**: 2024-11-07 10:30 UTC

### Failed Tests (3)

#### 1. TestUserAuthentication.test_login_timeout
**Root Cause**: Network timeout during authentication service call
**Confidence**: 85%
**Category**: Network/Timeout
**Suggestion**: Increase timeout from 5s to 10s or add retry logic
**Similar Issues**: 3 occurrences in last 7 days

#### 2. TestDataProcessor.test_null_input
**Root Cause**: NullPointerException in DataProcessor.process() line 45
**Confidence**: 95%
**Category**: Runtime/NullPointer
**Suggestion**: Add null check before accessing userData.getName()
**First Occurrence**: New issue

### Summary
- Total Failures: 3
- Resolved via Cache: 1
- New Issues: 2
- Estimated Fix Time: 30 minutes
```

### 5. Token Optimization Rules

1. **Log Compression**
   - Max 500 tokens per analysis
   - Focus on error stack traces
   - Remove duplicate lines
   - Strip ANSI color codes

2. **Batching Strategy**
   - Group up to 5 similar failures
   - Single Haiku call per batch
   - Share common context once

3. **Caching Policy**
   ```python
   CACHE_DURATION = {
       "high_confidence": 7200,    # 2 hours
       "medium_confidence": 3600,  # 1 hour
       "low_confidence": 900,      # 15 minutes
       "pattern_match": 1800       # 30 minutes
   }
   ```

### 6. Continuous Improvement

Track and improve these metrics:

1. **Accuracy Tracking**
   ```bash
   # Log successful fixes
   python src/utils/metrics.py --record-success --issue-id 123
   
   # Log false positives
   python src/utils/metrics.py --record-false-positive --issue-id 124
   ```

2. **Pattern Learning**
   - Add new patterns to `PatternMatcher` when confidence > 90%
   - Update regex patterns based on false negatives
   - Version control all pattern changes

3. **Self-Improvement Checklist**
   - [ ] Review weekly false positive rate
   - [ ] Identify most expensive token operations
   - [ ] Update caching strategy based on hit rates
   - [ ] Refine Haiku prompts for better accuracy
   - [ ] Add new CI system parsers as needed

## Error Handling

### Common Issues and Solutions

1. **GitHub Rate Limiting**
   ```python
   # Implement exponential backoff
   wait_time = min(300, 2 ** retry_count)
   ```

2. **Haiku Token Limit**
   ```python
   # Split large logs
   if estimated_tokens > 800:
       analyze_in_chunks(log, chunk_size=400)
   ```

3. **Database Lock**
   ```python
   # Use write-ahead logging
   conn.execute("PRAGMA journal_mode=WAL")
   ```

## Git Workflow

### Version Control Best Practices

```bash
# Feature branch for improvements
git checkout -b feature/improve-pattern-matching

# Commit atomic changes
git add src/analysis/pattern_matcher.py
git commit -m "Add pattern for TypeScript compilation errors"

# Track configuration changes
git add config/settings.yaml
git commit -m "Reduce Haiku temperature to 0.1 for consistency"

# Tag stable versions
git tag -a v1.2.0 -m "Improved Java exception handling"
git push origin v1.2.0
```

### Important Files to Track
- All source code in `src/`
- Configuration files in `config/`
- Pattern definitions
- Prompt templates
- Performance metrics logs

### Files to Ignore (.gitignore)
```
data/issues.db
data/cache/
logs/
venv/
__pycache__/
*.pyc
.env
```

## Performance Benchmarks

Maintain these performance targets:

| Operation | Target | Alert Threshold |
|-----------|--------|-----------------|
| Failure Detection | < 30s | > 60s |
| Analysis per Failure | < 5s | > 10s |
| Report Generation | < 2s | > 5s |
| Cache Lookup | < 100ms | > 500ms |
| Token Usage (Haiku) | < 500/analysis | > 800/analysis |
| Daily Token Budget | < 100k | > 150k |

## Advanced Scenarios

### Multi-Repository Failures
When the same test fails across multiple repos:
1. Identify common dependencies
2. Check for recent shared library updates
3. Generate consolidated report
4. Suggest coordinated fix

### Flaky Test Detection
Track intermittent failures:
```python
if failure_count > 3 and success_rate > 0.7:
    mark_as_flaky(test)
    suggest_retry_mechanism()
```

### Production Incident Correlation
Link CI failures to production issues:
1. Monitor deployment pipelines
2. Track feature flags
3. Correlate timing with incidents
4. Prioritize fixes accordingly

## Communication Templates

### GitHub PR Comment
```markdown
üîç **Build Detective Analysis**

Your CI build failed with 2 test failures. Here's what I found:

1. ‚ùå `TestAPI.test_timeout` - Network timeout (90% confident)
   - **Likely cause**: External service latency
   - **Suggested fix**: Add retry logic or increase timeout
   
2. ‚ùå `TestDB.test_connection` - Database connection refused (95% confident)
   - **Likely cause**: Test database not initialized
   - **Suggested fix**: Check database setup in CI environment

üìä These issues have occurred 3 times in the past week across different PRs.

[View detailed report](link) | [Mark as false positive](link)
```

### Slack Notification
```json
{
  "text": "CI Failure Detected",
  "attachments": [{
    "color": "danger",
    "title": "Build #1234 Failed",
    "text": "2 test failures analyzed",
    "fields": [
      {"title": "Confidence", "value": "92%", "short": true},
      {"title": "Est. Fix Time", "value": "15 min", "short": true}
    ]
  }]
}
```

## Remember

1. **Efficiency First**: Always check cache before running analysis
2. **Token Economy**: Use Haiku for 90% of analyses
3. **Learn and Adapt**: Update patterns based on outcomes
4. **Clear Communication**: Reports should be actionable
5. **Version Everything**: Track all improvements in Git

You are the orchestrator ensuring Build Detective runs smoothly, efficiently, and accurately. Make decisions that optimize for both cost and developer productivity.
