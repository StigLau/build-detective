"""
Report generator for Build Detective analysis results
"""
from typing import Dict, List, Any
from datetime import datetime

from utils.logger import setup_logger

logger = setup_logger(__name__)

class ReportGenerator:
    """Generate formatted reports from analysis results"""
    
    def generate(self, analysis_results: Dict[str, Any]) -> str:
        """
        Generate comprehensive analysis report
        
        Args:
            analysis_results: Results from Supervisor.analyze_failures()
            
        Returns:
            Formatted markdown report
        """
        if not analysis_results or analysis_results.get('status') == 'no_failures':
            return self._generate_no_failures_report()
        
        analyses = analysis_results.get('analyses', [])
        summary = analysis_results.get('summary', {})
        
        # Header
        report_lines = [
            "# üïµÔ∏è Build Detective Analysis Report",
            "",
            f"**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"**Status**: {analysis_results.get('status', 'Unknown')}",
            ""
        ]
        
        # Summary section
        report_lines.extend(self._generate_summary_section(analysis_results, summary))
        
        # Individual failure analyses
        if analyses:
            report_lines.extend(self._generate_failures_section(analyses))
        
        # Recommendations section
        report_lines.extend(self._generate_recommendations_section(analyses))
        
        # Footer
        report_lines.extend([
            "",
            "---",
            "",
            "*Generated by Build Detective - AI-powered CI/build failure analysis*",
            ""
        ])
        
        return "\n".join(report_lines)
    
    def _generate_no_failures_report(self) -> str:
        """Generate report when no failures found"""
        return """# üïµÔ∏è Build Detective Analysis Report

**Generated**: {timestamp}
**Status**: ‚úÖ All Clear

## Summary

No CI failures detected. All systems operational!

---

*Generated by Build Detective - AI-powered CI/build failure analysis*
""".format(timestamp=datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
    
    def _generate_summary_section(self, results: Dict, summary: Dict) -> List[str]:
        """Generate summary statistics section"""
        total = results.get('total_failures', 0)
        cached = results.get('cached_count', 0)
        new_analysis = results.get('new_analysis_count', 0)
        cost = results.get('estimated_cost', 0)
        
        avg_confidence = summary.get('avg_confidence', 0)
        high_confidence = summary.get('high_confidence', 0)
        escalated = summary.get('escalated', 0)
        
        lines = [
            "## üìä Summary",
            "",
            f"- **Total Failures**: {total}",
            f"- **Cached Solutions**: {cached}",
            f"- **New Analyses**: {new_analysis}",
            f"- **High Confidence (>80%)**: {high_confidence}",
            f"- **Escalated to Sonnet**: {escalated}",
            f"- **Average Confidence**: {avg_confidence:.1%}",
            f"- **Estimated Cost**: ${cost:.4f}",
            ""
        ]
        
        # Error type breakdown
        error_types = summary.get('error_types', {})
        if error_types:
            lines.extend([
                "### Error Type Breakdown",
                ""
            ])
            
            for error_type, count in sorted(error_types.items(), key=lambda x: x[1], reverse=True):
                emoji = self._get_error_type_emoji(error_type)
                lines.append(f"- {emoji} **{error_type.replace('_', ' ').title()}**: {count}")
            
            lines.append("")
        
        return lines
    
    def _generate_failures_section(self, analyses: List[Dict]) -> List[str]:
        """Generate detailed failure analyses section"""
        lines = [
            "## üîç Detailed Analysis",
            ""
        ]
        
        # Sort by confidence (highest first)
        sorted_analyses = sorted(analyses, key=lambda x: x.get('confidence', 0), reverse=True)
        
        for i, analysis in enumerate(sorted_analyses, 1):
            lines.extend(self._format_single_analysis(i, analysis))
        
        return lines
    
    def _format_single_analysis(self, index: int, analysis: Dict) -> List[str]:
        """Format single failure analysis"""
        confidence = analysis.get('confidence', 0)
        error_type = analysis.get('error_type', 'unknown')
        status = analysis.get('status', 'UNKNOWN')
        
        # Determine confidence emoji and color
        if confidence > 0.8:
            confidence_emoji = "üü¢"
            confidence_level = "High"
        elif confidence > 0.6:
            confidence_emoji = "üü°"
            confidence_level = "Medium"
        else:
            confidence_emoji = "üî¥"
            confidence_level = "Low"
        
        # Status emoji
        status_emoji = "‚ùå" if status == "FAILURE" else "‚ö†Ô∏è" if status == "PARTIAL" else "‚úÖ"
        
        # Error type emoji
        type_emoji = self._get_error_type_emoji(error_type)
        
        lines = [
            f"### {status_emoji} Failure {index}",
            "",
            f"**Primary Error**: {analysis.get('primary_error', 'Unknown error')}",
            f"**Type**: {type_emoji} {error_type.replace('_', ' ').title()}",
            f"**Confidence**: {confidence_emoji} {confidence_level} ({confidence:.1%})",
            f"**Impact**: {analysis.get('blocking_vs_warning', 'Unknown')}",
            ""
        ]
        
        # Suggested action
        action = analysis.get('suggested_action', '')
        if action:
            lines.extend([
                "**üí° Suggested Action**:",
                f"> {action}",
                ""
            ])
        
        # GitHub commands if available
        commands = analysis.get('github_commands', [])
        if commands:
            lines.extend([
                "**üîß GitHub Commands**:",
                ""
            ])
            for cmd in commands:
                lines.append(f"```bash\n{cmd}\n```")
            lines.append("")
        
        # Additional info for cached/escalated
        if analysis.get('source') == 'cache':
            lines.append("*üìã Solution retrieved from cache*")
            lines.append("")
        elif analysis.get('escalated'):
            lines.append("*üÜô Analysis escalated to Sonnet for review*")
            lines.append("")
        
        lines.append("---")
        lines.append("")
        
        return lines
    
    def _generate_recommendations_section(self, analyses: List[Dict]) -> List[str]:
        """Generate recommendations section"""
        if not analyses:
            return []
        
        lines = [
            "## üí° Recommendations",
            ""
        ]
        
        # Count error types for patterns
        error_type_counts = {}
        low_confidence_count = 0
        
        for analysis in analyses:
            error_type = analysis.get('error_type', 'unknown')
            error_type_counts[error_type] = error_type_counts.get(error_type, 0) + 1
            
            if analysis.get('confidence', 0) < 0.7:
                low_confidence_count += 1
        
        # Pattern-based recommendations
        if error_type_counts.get('docker_build', 0) > 1:
            lines.extend([
                "### üê≥ Docker Issues Detected",
                "",
                "Multiple Docker build failures suggest infrastructure issues:",
                "- Review Dockerfile syntax and COPY instructions",
                "- Check for malformed UV version specifiers (quote them)",
                "- Verify base image availability",
                ""
            ])
        
        if error_type_counts.get('dependency', 0) > 1:
            lines.extend([
                "### üì¶ Dependency Pattern",
                "",
                "Multiple dependency failures detected:",
                "- Consider adding `--extra dev` flags to install commands",
                "- Review requirements.txt/pyproject.toml for version conflicts",
                "- Check if test dependencies are properly specified",
                ""
            ])
        
        if low_confidence_count > len(analyses) // 2:
            lines.extend([
                "### ‚ö†Ô∏è Analysis Confidence",
                "",
                f"**{low_confidence_count}** analyses had low confidence scores.",
                "Consider:",
                "- Manual review of failed jobs",
                "- Gathering more context from recent commits",
                "- Checking if failures are related to infrastructure changes",
                ""
            ])
        
        # General recommendations
        lines.extend([
            "### üöÄ Next Steps",
            "",
            "1. **Address high-confidence failures first** - they have clear solutions",
            "2. **Review recurring patterns** - fix root causes, not just symptoms", 
            "3. **Update CI configuration** if infrastructure issues are detected",
            "4. **Consider adding retry logic** for flaky network-dependent tests",
            ""
        ])
        
        return lines
    
    def _get_error_type_emoji(self, error_type: str) -> str:
        """Get emoji for error type"""
        emoji_map = {
            'docker_build': 'üê≥',
            'dependency': 'üì¶',
            'python_import': 'üêç',
            'compilation': '‚öôÔ∏è',
            'git': 'üìù',
            'timeout': '‚è∞',
            'permission': 'üîê',
            'network': 'üåê',
            'cache': 'üíæ',
            'analysis_failure': 'ü§ñ',
            'other': '‚ùì',
            'unknown': '‚ùì'
        }
        return emoji_map.get(error_type, '‚ùì')
    
    def generate_summary_only(self, analysis_results: Dict[str, Any]) -> str:
        """Generate brief summary for quick overview"""
        if not analysis_results or analysis_results.get('status') == 'no_failures':
            return "‚úÖ No CI failures detected"
        
        total = analysis_results.get('total_failures', 0)
        summary = analysis_results.get('summary', {})
        high_confidence = summary.get('high_confidence', 0)
        avg_confidence = summary.get('avg_confidence', 0)
        
        return f"üïµÔ∏è Build Detective: {total} failures analyzed, {high_confidence} high-confidence solutions, {avg_confidence:.1%} avg confidence"